{"questionId": "1271", "acRate": 68.08351849653137, "difficulty": "Medium", "freqBar": 57.39762034394123, "frontendQuestionId": "1236", "paidOnly": true, "status": "ac", "title": "Web Crawler", "topicTags": [{"name": "String", "id": "VG9waWNUYWdOb2RlOjEw", "slug": "string"}, {"name": "Depth-First Search", "id": "VG9waWNUYWdOb2RlOjIx", "slug": "depth-first-search"}, {"name": "Breadth-First Search", "id": "VG9waWNUYWdOb2RlOjIy", "slug": "breadth-first-search"}, {"name": "Interactive", "id": "VG9waWNUYWdOb2RlOjYxMDU5", "slug": "interactive"}], "titleSlug": "web-crawler", "content": "<p>Given a url <code>startUrl</code> and an interface <code>HtmlParser</code>, implement a web&nbsp;crawler to crawl all links that are under the&nbsp;<strong>same hostname</strong> as&nbsp;<code>startUrl</code>.&nbsp;</p>\n\n<p>Return&nbsp;all urls obtained by your web crawler in <strong>any</strong> order.</p>\n\n<p>Your crawler should:</p>\n\n<ul>\n\t<li>Start from the page: <code>startUrl</code></li>\n\t<li>Call <code>HtmlParser.getUrls(url)</code> to get all urls from a webpage of given url.</li>\n\t<li>Do not crawl the same link twice.</li>\n\t<li>Explore only the links that are under the <strong>same hostname</strong> as <code>startUrl</code>.</li>\n</ul>\n\n<p><img alt=\"\" src=\"https://assets.leetcode.com/uploads/2019/08/13/urlhostname.png\" style=\"width: 600px; height: 164px;\" /></p>\n\n<p>As shown in the example url above, the hostname is <code>example.org</code>. For simplicity sake, you may assume all&nbsp;urls use <strong>http protocol</strong> without any&nbsp;<strong>port</strong> specified. For example, the urls&nbsp;<code>http://leetcode.com/problems</code> and&nbsp;<code>http://leetcode.com/contest</code> are under the same hostname, while urls <code>http://example.org/test</code> and <code>http://example.com/abc</code> are not under the same hostname.</p>\n\n<p>The <code>HtmlParser</code> interface is defined as such:&nbsp;</p>\n\n<pre>\ninterface HtmlParser {\n  // Return a list of all urls from a webpage of given <em>url</em>.\n  public List&lt;String&gt; getUrls(String url);\n}</pre>\n\n<p>Below&nbsp;are two examples explaining the functionality of the problem, for custom testing purposes you&#39;ll have three&nbsp;variables&nbsp;<code data-stringify-type=\"code\">urls</code>,&nbsp;<code data-stringify-type=\"code\">edges</code>&nbsp;and&nbsp;<code data-stringify-type=\"code\">startUrl</code>. Notice that you will only have access to&nbsp;<code data-stringify-type=\"code\">startUrl</code>&nbsp;in your code, while&nbsp;<code data-stringify-type=\"code\">urls</code>&nbsp;and&nbsp;<code data-stringify-type=\"code\">edges</code>&nbsp;are not directly accessible to you in code.</p>\n\n<p>Note: Consider the same URL with the trailing slash &quot;/&quot; as a different URL. For example, &quot;http://news.yahoo.com&quot;, and &quot;http://news.yahoo.com/&quot; are different urls.</p>\n\n<p>&nbsp;</p>\n<p><strong class=\"example\">Example 1:</strong></p>\n\n<p><img alt=\"\" src=\"https://assets.leetcode.com/uploads/2019/10/23/sample_2_1497.png\" style=\"width: 610px; height: 300px;\" /></p>\n\n<pre>\n<strong>Input:\n</strong>urls = [\n&nbsp; &quot;http://news.yahoo.com&quot;,\n&nbsp; &quot;http://news.yahoo.com/news&quot;,\n&nbsp; &quot;http://news.yahoo.com/news/topics/&quot;,\n&nbsp; &quot;http://news.google.com&quot;,\n&nbsp; &quot;http://news.yahoo.com/us&quot;\n]\nedges = [[2,0],[2,1],[3,2],[3,1],[0,4]]\nstartUrl = &quot;http://news.yahoo.com/news/topics/&quot;\n<strong>Output:</strong> [\n&nbsp; &quot;http://news.yahoo.com&quot;,\n&nbsp; &quot;http://news.yahoo.com/news&quot;,\n&nbsp; &quot;http://news.yahoo.com/news/topics/&quot;,\n&nbsp; &quot;http://news.yahoo.com/us&quot;\n]\n</pre>\n\n<p><strong class=\"example\">Example 2:</strong></p>\n\n<p><strong><img alt=\"\" src=\"https://assets.leetcode.com/uploads/2019/10/23/sample_3_1497.png\" style=\"width: 540px; height: 270px;\" /></strong></p>\n\n<pre>\n<strong>Input:</strong> \nurls = [\n&nbsp; &quot;http://news.yahoo.com&quot;,\n&nbsp; &quot;http://news.yahoo.com/news&quot;,\n&nbsp; &quot;http://news.yahoo.com/news/topics/&quot;,\n&nbsp; &quot;http://news.google.com&quot;\n]\nedges = [[0,2],[2,1],[3,2],[3,1],[3,0]]\nstartUrl = &quot;http://news.google.com&quot;\n<strong>Output:</strong> [&quot;http://news.google.com&quot;]\n<strong>Explanation: </strong>The startUrl links to all other pages that do not share the same hostname.</pre>\n\n<p>&nbsp;</p>\n<p><strong>Constraints:</strong></p>\n\n<ul>\n\t<li><code>1 &lt;= urls.length &lt;= 1000</code></li>\n\t<li><code>1 &lt;= urls[i].length &lt;= 300</code></li>\n\t<li><code>startUrl</code>&nbsp;is one of the <code>urls</code>.</li>\n\t<li>Hostname label must be from 1 to 63 characters long, including the dots, may contain only the ASCII letters from &#39;a&#39; to&nbsp;&#39;z&#39;, digits&nbsp; from &#39;0&#39; to &#39;9&#39; and the&nbsp;hyphen-minus&nbsp;character (&#39;-&#39;).</li>\n\t<li>The hostname may not start or end with&nbsp;the hyphen-minus character (&#39;-&#39;).&nbsp;</li>\n\t<li>See:&nbsp;&nbsp;<a href=\"https://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_hostnames\">https://en.wikipedia.org/wiki/Hostname#Restrictions_on_valid_hostnames</a></li>\n\t<li>You may assume there&#39;re&nbsp;no duplicates in url library.</li>\n</ul>\n", "hints": ["Use DFS/BFS to search start from the startURL. Remember to get rid of duplicate URLs."], "exampleTestcases": "[\"http://news.yahoo.com\",\"http://news.yahoo.com/news\",\"http://news.yahoo.com/news/topics/\",\"http://news.google.com\",\"http://news.yahoo.com/us\"]\n[[2,0],[2,1],[3,2],[3,1],[0,4]]\n\"http://news.yahoo.com/news/topics/\"\n[\"http://news.yahoo.com\",\"http://news.yahoo.com/news\",\"http://news.yahoo.com/news/topics/\",\"http://news.google.com\"]\n[[0,2],[2,1],[3,2],[3,1],[3,0]]\n\"http://news.google.com\"", "codeSnippets": [{"lang": "C++", "langSlug": "cpp", "code": "/**\n * // This is the HtmlParser's API interface.\n * // You should not implement it, or speculate about its implementation\n * class HtmlParser {\n *   public:\n *     vector<string> getUrls(string url);\n * };\n */\n\nclass Solution {\npublic:\n    vector<string> crawl(string startUrl, HtmlParser htmlParser) {\n        \n    }\n};"}, {"lang": "Java", "langSlug": "java", "code": "/**\n * // This is the HtmlParser's API interface.\n * // You should not implement it, or speculate about its implementation\n * interface HtmlParser {\n *     public List<String> getUrls(String url) {}\n * }\n */\n\nclass Solution {\n    public List<String> crawl(String startUrl, HtmlParser htmlParser) {\n        \n    }\n}"}, {"lang": "Python", "langSlug": "python", "code": "# \"\"\"\n# This is HtmlParser's API interface.\n# You should not implement it, or speculate about its implementation\n# \"\"\"\n#class HtmlParser(object):\n#    def getUrls(self, url):\n#        \"\"\"\n#        :type url: str\n#        :rtype List[str]\n#        \"\"\"\n\nclass Solution(object):\n    def crawl(self, startUrl, htmlParser):\n        \"\"\"\n        :type startUrl: str\n        :type htmlParser: HtmlParser\n        :rtype: List[str]\n        \"\"\"\n        "}, {"lang": "Python3", "langSlug": "python3", "code": "# \"\"\"\n# This is HtmlParser's API interface.\n# You should not implement it, or speculate about its implementation\n# \"\"\"\n#class HtmlParser(object):\n#    def getUrls(self, url):\n#        \"\"\"\n#        :type url: str\n#        :rtype List[str]\n#        \"\"\"\n\nclass Solution:\n    def crawl(self, startUrl: str, htmlParser: 'HtmlParser') -> List[str]:\n        "}, {"lang": "C#", "langSlug": "csharp", "code": "/**\n * // This is the HtmlParser's API interface.\n * // You should not implement it, or speculate about its implementation\n * class HtmlParser {\n *     public List<String> GetUrls(String url) {}\n * }\n */\n\nclass Solution {\n    public IList<string> Crawl(string startUrl, HtmlParser htmlParser) {\n        \n    }\n}"}, {"lang": "JavaScript", "langSlug": "javascript", "code": "/**\n * // This is the HtmlParser's API interface.\n * // You should not implement it, or speculate about its implementation\n * function HtmlParser() {\n *\n *\t\t@param {string} url\n *     \t@return {string[]}\n *     \tthis.getUrls = function(url) {\n *      \t...\n *     \t};\n * };\n */\n\n/**\n * @param {string} startUrl\n * @param {HtmlParser} htmlParser\n * @return {string[]}\n*/\nvar crawl = function(startUrl, htmlParser) {\n    \n};"}, {"lang": "TypeScript", "langSlug": "typescript", "code": "/**\n * // This is the HtmlParser's API interface.\n * // You should not implement it, or speculate about its implementation\n * class HtmlParser {\n *      getUrls(url: string): string[] {}\n * }\n */\n\nfunction crawl(startUrl: string, htmlParser: HtmlParser): string[] {\n\t\n};"}, {"lang": "PHP", "langSlug": "php", "code": "/**\n * // This is the HtmlParser's API interface.\n * // You should not implement it, or speculate about its implementation\n * class  {\n *     public function getUrls($url) {}\n * }\n */\n\nclass Solution {\n    /**\n     * @param String $startUrl\n     * @param HtmlParser $htmlParser\n     * @return String[]\n     */\n    function crawl($startUrl, $htmlParser) {\n\t\t\n\t}\n}"}, {"lang": "Swift", "langSlug": "swift", "code": "/**\n * // This is the HtmlParser's API interface.\n * // You should not implement it, or speculate about its implementation\n * public class HtmlParser {\n *     public func getUrls(_ url: String) -> [String] {}\n * }\n */\n\nclass Solution {   \n    func crawl(_ startUrl: String, _ htmlParser: HtmlParser) -> [String] {\n        \n    }\n}"}, {"lang": "Kotlin", "langSlug": "kotlin", "code": "/**\n * // This is the HtmlParser's API interface.\n * // You should not implement it, or speculate about its implementation\n * class HtmlParser {\n *     fun getUrls(url:String):List<String> {}\n * }\n */\n\nclass Solution {\n    fun crawl(startUrl:String, htmlParser:HtmlParser):List<String> {\n        \n    }\n}"}, {"lang": "Go", "langSlug": "golang", "code": "/**\n * // This is HtmlParser's API interface.\n * // You should not implement it, or speculate about its implementation\n * type HtmlParser struct {\n *     func GetUrls(url string) []string {}\n * }\n */\n\nfunc crawl(startUrl string, htmlParser HtmlParser) []string {\n    \n}"}, {"lang": "Ruby", "langSlug": "ruby", "code": "# This is HtmlParser's API interface.\n# You should not implement it, or speculate about its implementation\n# class HtmlParser\n#     def getUrls(url)\n#         @return {List[String]}\n#     end\n# end\n\n# @param {String} startUrl\n# @param {HtmlParser} htmlParser\n# @return {String}\ndef crawl(startUrl, htmlParser)\n    \nend"}, {"lang": "Scala", "langSlug": "scala", "code": "/**\n * // This is the HtmlParser's API interface.\n * // You should not implement it, or speculate about its implementation\n * class HtmlParser {\n *     def getUrls(url: String): List[String] = {}\n * }\n */\n\nobject Solution {\n    def crawl(startUrl: String, htmlParser: HtmlParser): Array[String] = {\n    \t\n    }\n}"}], "similarQuestionList": [{"difficulty": "Medium", "titleSlug": "web-crawler-multithreaded", "title": "Web Crawler Multithreaded", "isPaidOnly": true}]}